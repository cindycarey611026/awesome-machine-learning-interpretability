### Scholarly Literature on Responsible AI
* [50 Years of Test (Un)fairness: Lessons for Machine Learning](https://arxiv.org/pdf/1811.10104.pdf)
* [A Comparative Study of Fairness-Enhancing Interventions in Machine Learning](https://arxiv.org/pdf/1802.04422.pdf)
* [A Survey Of Methods For Explaining Black Box Models](https://arxiv.org/pdf/1802.01933.pdf)
* [A Marauder’s Map of Security and Privacy in Machine Learning](https://arxiv.org/pdf/1811.01134.pdf)
* [Challenges for Transparency](https://arxiv.org/pdf/1708.01870.pdf)
* [Closing the AI Accountability Gap](https://arxiv.org/pdf/2001.00973.pdf)
* [DQI: Measuring Data Quality in NLP](https://arxiv.org/pdf/2005.00816.pdf)
* [Explaining by Removing: A Unified Framework for Model Explanation](https://arxiv.org/abs/2011.14878)
* [Explaining Explanations: An Overview of Interpretability of Machine Learning](https://arxiv.org/pdf/1806.00069.pdf)
* [Explanation in Human-AI Systems: A Literature Meta-Review, Synopsis of Key Ideas and Publications, and Bibliography for Explainable AI](https://arxiv.org/abs/1902.01876v1)
* [Interpretable Machine Learning: Definitions, Methods, and Applications](https://arxiv.org/abs/1901.04592)
* [Limitations of Interpretable Machine Learning](https://compstat-lmu.github.io/iml_methods_limitations/)
* [Machine Learning Explainability in Finance](https://www.bankofengland.co.uk/-/media/boe/files/working-paper/2019/machine-learning-explainability-in-finance-an-application-to-default-risk-analysis)
* [On the Art and Science of Machine Learning Explanations](https://arxiv.org/pdf/1810.02909.pdf)
* [Please Stop Explaining Black Box Models for High-Stakes Decisions](https://arxiv.org/pdf/1811.10154.pdf)
* [Software Engineering for Machine Learning: A Case Study](https://www.microsoft.com/en-us/research/uploads/prod/2019/03/amershi-icse-2019_Software_Engineering_for_Machine_Learning.pdf)
* [The Mythos of Model Interpretability](https://arxiv.org/pdf/1606.03490.pdf)
* [Towards A Rigorous Science of Interpretable Machine Learning](https://arxiv.org/pdf/1702.08608.pdf)
* [Toward Trustworthy AI Development: Mechanisms for Supporting Verifiable Claims](https://arxiv.org/pdf/2004.07213.pdf)
* [The Security of Machine Learning](https://people.eecs.berkeley.edu/~adj/publications/paper-files/SecML-MLJ2010.pdf)
* [Techniques for Interpretable Machine Learning](https://arxiv.org/pdf/1808.00033.pdf)
* [Trends and Trajectories for Explainable, Accountable and Intelligible Systems: An HCI Research Agenda](https://dl.acm.org/citation.cfm?id=3174156)
* [Underspecification Presents Challenges for Credibility in Modern Machine Learning](https://arxiv.org/pdf/2011.03395.pdf)

# Curated Bibliographies
## NIST Playbook Measure FullLaunch
* Abebe, Rediet, and Kira Goldner. "Mechanism Design for Social Good." *AI Matters* 4, no. 3 (October 2018): 27--34. https://doi.org/10.1145/3284751.3284761.
* Barocas, Solon, Anhong Guo, Ece Kamar, Jacquelyn Krones, Meredith Ringel Morris, Jennifer Wortman Vaughan, W. Duncan Wadsworth, and Hanna Wallach. "Designing Disaggregated Evaluations of AI Systems: Choices, Considerations, and Tradeoffs." *Proceedings of the 2021 AAAI/ACM Conference on AI, Ethics, and Society*, July 2021, 368--78. https://doi.org/10.1145/3461702.3462610.
* Barredo Arrieta, Alejandro, Natalia Díaz-Rodríguez, Javier Del Ser, Adrien Bennetot, Siham Tabik, Alberto Barbado, Salvador Garcia, et al. "Explainable Artificial Intelligence (XAI): Concepts, Taxonomies, Opportunities, and Challenges Toward Responsible AI." *Information Fusion* 58 (June 2020): 82--115. https://doi.org/10.1016/j.inffus.2019.12.012.
* Barrett, Matthew P. "Framework for Improving Critical Infrastructure Cybersecurity Version 1.1." *National Institute of Standards and Technology (NIST)*, April 16, 2018. https://doi.org/10.6028/nist.cswp.04162018.
* Bender, Emily M., and Batya Friedman. "Data Statements for Natural Language Processing: Toward Mitigating System Bias and Enabling Better Science." *Transactions of the Association for Computational Linguistics* 6 (2018): 587--604. https://doi.org/10.1162/tacl_a_00041.
* Benthall, Sebastian, Seda Gürses, and Helen Nissenbaum. "Contextual Integrity through the Lens of Computer Science." *Foundations and Trends in Privacy and Security* 2, no. 1 (December 22, 2017): 1--69. https://doi.org/10.1561/3300000016.
* Bhattacharyya, Asit, and Lorne Cummings. "Measuring Corporate Environmental Performance -* Stakeholder Engagement Evaluation." *Business Strategy and the Environment* 24, no. 5 (2013): 309--25. https://doi.org/10.1002/bse.1819.
* Bishop, Christopher M. *Pattern Recognition and Machine Learning*. New York City, New York: Springer, 2006.
* Boyd, Karen. "Designing Up with Value-Sensitive Design: Building a Field Guide for Ethical ML Development." *FAccT '22: 2022 ACM Conference on Fairness, Accountability, and Transparency*, June 20, 2022, 2069--82. https://doi.org/10.1145/3531146.3534626.
* Brown, Shea, Ryan Carrier, Merve Hickok, and Adam Leon Smith. "Bias Mitigation in Data Sets." *SocArXiv*, July 8, 2021. https://doi.org/10.31235/osf.io/z8qrb.
* Buolamwini, Joy, and Timnit Gebru. "Gender Shades: Intersectional Accuracy Disparities in Commercial Gender Classification." *Proceedings of the 1st Conference on Fairness, Accountability and Transparency in PMLR* 81 (2018): 77--91. https://doi.org/https://proceedings.mlr.press/v81/buolamwini18a.html.
* Buçinca, Zana, Phoebe Lin, Krzysztof Z. Gajos, and Elena L. Glassman. "Proxy Tasks and Subjective Measures Can Be Misleading in Evaluating Explainable AI Systems." *IUI '20: Proceedings of the 25th International Conference on Intelligent User Interfaces*, March 17, 2020, 454--64. https://doi.org/10.1145/3377325.3377498.
* Caliskan, Aylin, Joanna J. Bryson, and Arvind Narayanan. "Semantics Derived Automatically from Language Corpora Contain Human-Like Biases." *Science* 356, no. 6334 (April 14, 2017): 183--86. https://doi.org/10.1126/science.aal4230.
* Chouldechova, Alexandra. "Fair Prediction with Disparate Impact: A Study of Bias in Recidivism Prediction Instruments." *Big Data* 5, no. 2 (June 1, 2017): 153--63. https://doi.org/10.1089/big.2016.0047.
* Cobbe, Jennifer, Michelle Seng Lee, and Jatinder Singh. "Reviewable Automated Decision-Making: A Framework for Accountable Algorithmic Systems." *FAccT '21: Proceedings of the 2021 ACM Conference on Fairness, Accountability, and Transparency*, March 1, 2021, 598--609. https://doi.org/10.1145/3442188.3445921.
* Costanza-Chock, Sasha. *Design Justice: Community-Led Practices to Build the Worlds We Need*. Cambridge: The MIT Press, 2020.
* Davis, Janet, and Lisa P. Nathan. "Value Sensitive Design: Applications, Adaptations, and Critiques." Edited by Jeroen van den Hoven, Pieter E. Vermaas, and Ibo van de Poel. *Handbook of Ethics, Values, and Technological Design*, January 1, 2015, 11--40. https://doi.org/10.1007/978-94-007-6970-0_3.
* Dcass, Microsoft. "Community Jury." Microsoft Learn's Azure Application Architecture Guide, 2023. https://learn.microsoft.com/en-us/azure/architecture/guide/responsible-innovation/community-jury/.
* Dobbe, Roel, Thomas Krendl Gilbert, and Yonatan Mintz. "Hard Choices in Artificial Intelligence." *Artificial Intelligence* 300 (November 2021). https://doi.org/10.1016/j.artint.2021.103555.
* Dwork, Cynthia. "Differential Privacy." *Automata, Languages and Programming*, 2006, 1--12. https://doi.org/10.1007/11787006_1.
* Fairlearn. "Fairness in Machine Learning." Fairlearn 0.8.0 Documentation, n.d. https://fairlearn.org/v0.8/user_guide/fairness_in_machine_learning.html#.
* Fazelpour, Sina, and Maria De-Arteaga. "Diversity in Sociotechnical Machine Learning Systems." *Big Data and Society* 9, no. 1 (2022). https://doi.org/10.1177/20539517221082027.
* Fazelpour, Sina, and Zachary C. Lipton. "Algorithmic Fairness from a Non-Ideal Perspective." *AIES '20: Proceedings of the AAAI/ACM Conference on AI, Ethics, and Society*, February 7, 2020, 57--63. https://doi.org/10.1145/3375627.3375828.
* Franklin, Jade S., Karan Bhanot, Mohamed Ghalwash, Kristin P. Bennett, Jamie McCusker, and Deborah L. McGuinness. "An Ontology for Fairness Metrics." *AIES '22: Proceedings of the 2022 AAAI/ACM Conference on AI, Ethics, and Society*, July 2022, 265--75. https://doi.org/10.1145/3514094.3534137.
* Friedman, Batya, and David G. Hendry. *Value Sensitive Design: Shaping Technology with Moral Imagination*. Cambridge, MA: The MIT Press, 2019.
* Friedman, Batya, David G. Hendry, and Alan Borning. "A Survey of Value Sensitive Design Methods." *Foundations and Trends in Human-Computer Interaction* 11, no. 2 (November 22, 2017): 63--125. https://doi.org/10.1561/1100000015.
* Fry, Hannah. *Hello World: Being Human in the Age of Algorithms*. New York: W.W. Norton & Company, 2018.
* Givens, Alexandra Reeve, and Meredith Ringel Morris. "Centering Disability Perspectives in Algorithmic Fairness, Accountability, & Transparency." *FAT* '20: Proceedings of the 2020 Conference on Fairness, Accountability, and Transparency*, January 27, 2020, 684--684. https://doi.org/10.1145/3351095.3375686.
* Google Developers. "Overview of Debugging ML Models." Google Developers Machine Learning Foundational Courses, n.d. https://developers.google.com/machine-learning/testing-debugging/common/overview.
* Green, Ben. "Escaping the Impossibility of Fairness: From Formal to Substantive Algorithmic Fairness." *Philosophy and Technology* 35, no. 90 (October 8, 2022). https://doi.org/10.1007/s13347-022-00584-6.
* Hall, Patrick. "Strategies for Model Debugging." Towards Data Science, November 8, 2019. https://towardsdatascience.com/strategies-for-model-debugging-aa822f1097ce.
* Hart, Diane, Gabi Diercks-O'Brien, and Adrian Powell. "Exploring Stakeholder Engagement in Impact Evaluation Planning in Educational Development Work." *Evaluation* 15, no. 3 (2009): 285--306. https://doi.org/10.1177/1356389009105882.
* Harvard University Privacy Tools Project. "Differential Privacy." Harvard University, n.d. https://privacytools.seas.harvard.edu/differential-privacy.
* Hasan, Ali, Shea Brown, Jovana Davidovic, Benjamin Lange, and Mitt Regan. "Algorithmic Bias and Risk Assessments: Lessons from Practice." *Digital Society* 1 (2022). https://doi.org/10.1007/s44206-022-00017-z.
* Hastie, Trevor, Robert Tibshirani, and Jerome Friedman. *The Elements of Statistical Learning: Data Mining, Inference, and Prediction*. 2nd ed. Springer-Verlag, 2009.
* Hendricks, Sharief, Nailah Conrad, Tania S. Douglas, and Tinashe Mutsvangwa. "A Modified Stakeholder Participation Assessment Framework for Design Thinking in Health Innovation." *Healthcare* 6, no. 3 (September 2018): 191--96. https://doi.org/10.1016/j.hjdsi.2018.06.003.
* Hutson, Matthew. "Measuring AI's Carbon Footprint: New Tools Track and Reduce Emissions from Machine Learning." IEEE Spectrum, November 22, 2022. https://spectrum.ieee.org/ai-carbon-footprint.
* IBM. "IBM's Principles of Chaos Engineering." IBM, n.d. https://www.ibm.com/cloud/architecture/architecture/practices/chaos-engineering-principles/.
* IEEE Computer Society. "Software Engineering Body of Knowledge Version 3: IEEE Computer Society." IEEE Computer Society. Accessed January 21, 2023. https://www.computer.org/education/bodies-of-knowledge/software-engineering/v3.
* "ISO/IEC TR 24027:2021." ISO, November 2021. https://www.iso.org/standard/77607.html.
* Jacobs, Abigail Z., and Hanna Wallach. "Measurement and Fairness." *FAccT '21: Proceedings of the 2021 ACM Conference on Fairness, Accountability, and Transparency*, March 2021, 375--85. https://doi.org/10.1145/3442188.3445901.
* Jo, Eun Seo, and Timnit Gebru. "Lessons from Archives: Strategies for Collecting Sociocultural Data in Machine Learning." *FAT* '20: Proceedings of the 2020 Conference on Fairness, Accountability, and Transparency*, January 2020, 306--16. https://doi.org/10.1145/3351095.3372829.
* Jordan, Sara R. "Designing Artificial Intelligence Review Boards: Creating Risk Metrics for Review of AI." *2019 IEEE International Symposium on Technology and Society (ISTAS)*, 2019. https://doi.org/10.1109/istas48451.2019.8937942.
* Kay, Matthew, Cynthia Matuszek, and Sean A. Munson. "Unequal Representation and Gender Stereotypes in Image Search Results for Occupations." *CHI '15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems*, April 18, 2015, 3819--28. https://doi.org/10.1145/2702123.2702520.
* Kroll, Joshua A. "Outlining Traceability: A Principle for Operationalizing Accountability in Computing Systems." *FAccT '21: Proceedings of the 2021 ACM Conference on Fairness, Accountability, and Transparency*, March 1, 2021, 758--71. https://doi.org/10.1145/3442188.3445937.
* Lamba, Hemank, Kit T. Rodolfa, and Rayid Ghani. "An Empirical Comparison of Bias Reduction Methods on Real-World Problems in High-Stakes Policy Settings." *ACM SIGKDD Explorations Newsletter* 23, no. 1 (May 29, 2021): 69--85. https://doi.org/10.1145/3468507.3468518.
* Landers, Richard N., and Tara S. Behrend. "Auditing the AI Auditors: A Framework for Evaluating Fairness and Bias in High Stakes AI Predictive Models." *American Psychologist* 78, no. 1 (2023): 36--49. https://doi.org/10.1037/amp0000972.
* Loi, Michele, and Christoph Heitz. "Is Calibration a Fairness Requirement?" *FAccT '22: 2022 ACM Conference on Fairness, Accountability, and Transparency*, June 2022, 2026--34. https://doi.org/10.1145/3531146.3533245.
* Machanavajjhala, Ashwin, Johannes Gehrke, Daniel Kifer, and Muthuramakrishnan Venkitasubramaniam. "L-Diversity: Privacy beyond K-Anonymity." *22nd International Conference on Data Engineering (ICDE'06)*, 2006. https://doi.org/10.1109/icde.2006.1.
* Margetis, George, Stavroula Ntoa, Margherita Antona, and Constantine Stephanidis. "Human-Centered Design of Artificial Intelligence." Essay. In *Handbook of Human Factors and Ergonomics*, edited by Gavriel Salvendy and Waldemar Karwowski, 5th ed., 1085--1106. S: John Wiley & Sons, 2021.
* MathWorks. "Explore Fairness Metrics for Credit Scoring Model." MATLAB & Simulink, 2023. https://www.mathworks.com/help/risk/explore-fairness-metrics-for-credit-scoring-model.html.
* McGraw, Gary, Harold Figueroa, Victor Shepardson, and Richie Bonett. "BIML Interactive Machine Learning Risk Framework." Berryville Institute of Machine Learning (BIML), 2022. https://berryvilleiml.com/interactive/.
* Mehrabi, Ninareh, Fred Morstatter, Nripsuta Saxena, Kristina Lerman, and Aram Galstyan. "A Survey on Bias and Fairness in Machine Learning." *ACM Computing Surveys* 54, no. 6 (July 2021): 1--35. https://doi.org/10.1145/3457607.
* Metcalf, Jacob, and Kate Crawford. "Where Are Human Subjects in Big Data Research? The Emerging Ethics Divide." *Big Data and Society* 3, no. 1 (Spring 2016). https://doi.org/10.1177/2053951716650211.
* Microsoft Research. "AI Fairness Checklist." Microsoft, February 7, 2022. https://www.microsoft.com/en-us/research/project/ai-fairness-checklist/.
* Mitchell, Margaret, Simone Wu, Andrew Zaldivar, Parker Barnes, Lucy Vasserman, Ben Hutchinson, Elena Spitzer, Inioluwa Deborah Raji, and Timnit Gebru. "Model Cards for Model Reporting." *FAT *19: Proceedings of the Conference on Fairness, Accountability, and Transparency*, January 2019, 220--29. https://doi.org/10.1145/3287560.3287596.
* Mitre, Mitre Corporation. "Mitre/Advmlthreatmatrix: Adversarial Threat Landscape for AI Systems." GitHub, n.d. https://github.com/mitre/advmlthreatmatrix.
* Moss, Emanuel, Elizabeth Watkins, Ranjit Singh, Madeleine Clare Elish, and Jacob Metcalf. "Assembling Accountability: Algorithmic Impact Assessment for the Public Interest." *SSRN*, July 8, 2021. https://doi.org/10.2139/ssrn.3877437.
* Narayanan, Arvind. "Tl;DS * 21 Fairness Definition and Their Politics by Arvind Narayanan." Dora's world, July 19, 2019. https://shubhamjain0594.github.io/post/tlds-arvind-fairness-definitions/.
* National Institute of Standards and Technology (NIST). "Cybersecurity Framework." NIST, 2023. https://www.nist.gov/cyberframework.
* National Institutes of Health. "Definition of Human Subjects Research." NIH Central Resource for Grants and Funding Information, January 13, 2020. https://grants.nih.gov/policy/humansubjects/research.htm.
* Noble, Safiya Umoja. *Algorithms of Oppression: How Search Engines Reinforce Racism*. New York, NY: New York University Press, 2018.
* Obermeyer, Ziad, Brian Powers, Christine Vogeli, and Sendhil Mullainathan. "Dissecting Racial Bias in an Algorithm Used to Manage the Health of Populations." *Science* 366, no. 6464 (October 25, 2019): 447--53. https://doi.org/10.1126/science.aax2342.
* Office for Human Research Protections (OHRP). "45 CFR 46." United States Department of Health and Human Services Office for Human Research Protections, March 10, 2021. https://www.hhs.gov/ohrp/regulations-and-policy/regulations/45-cfr-46/index.html.
* Passi, Samir, and Solon Barocas. "Problem Formulation and Fairness." *FAT* '19: Proceedings of the Conference on Fairness, Accountability, and Transparency*, January 2019, 39--48. https://doi.org/10.1145/3287560.3287567.
* Patton, Jeff, Peter Economy, Martin Fowler, Alan Cooper, and Marty Cagan. *User Story Mapping: Discover the Whole Story, Build the Right Product*. O'Reilly, 2014.
* Paulk, Mark C., Bill Curtis, Mary Beth Chrissis, and Charles V. Weber. "Capability Maturity Model, Version 1.1." *IEEE Software* 10, no. 4 (1993): 18--27. https://doi.org/10.1109/52.219617.
* Paullada, Amandalynne, Inioluwa Deborah Raji, Emily M. Bender, Emily Denton, and Alex Hanna. "Data and Its (Dis)Contents: A Survey of Dataset Development and Use in Machine Learning Research." *Patterns* 2, no. 11 (2021): 100336. https://doi.org/10.1016/j.patter.2021.100336.
* Piano, Luca, Fabio Garcea, Valentina Gatteschi, Fabrizio Lamberti, and Lia Morra. "Detecting Drift in Deep Learning: A Methodology Primer." *IT Professional* 24, no. 5 (2022): 53--60. https://doi.org/10.1109/mitp.2022.3191318.
* Raji, Inioluwa Deborah, I. Elizabeth Kumar, Aaron Horowitz, and Andrew Selbst. "The Fallacy of AI Functionality." *FAccT '22: 2022 ACM Conference on Fairness, Accountability, and Transparency*, June 2022, 959--72. https://doi.org/10.1145/3531146.3533158.
* Robinson, David G. *Voices in the Code: A Story About People, Their Values, and the Algorithm They Made*. New York: Russell Sage Foundation, 2022.
* Saxena, Devansh, Karla Badillo-Urquiola, Pamela J. Wisniewski, and Shion Guha. "A Human-Centered Review of Algorithms Used within the U.S. Child Welfare System." *CHI '20: Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems*, April 23, 2020, 1--15. https://doi.org/10.1145/3313831.3376229.
* Schiff, Daniel, Aladdin Ayesh, Laura Musikanski, and John C. Havens. "IEEE 7010: A New Standard for Assessing the Well-Being Implications of Artificial Intelligence." *2020 IEEE International Conference on Systems, Man, and Cybernetics (SMC)*, 2020. https://doi.org/10.1109/smc42975.2020.9283454.
* Schmidt, Victor, Alexandra Luccioni, Alexandre Lacoste, and Thomas Dandres. "Machine Learning CO2 Impact Calculator." ML CO2 Impact, n.d. https://mlco2.github.io/impact/.
* Schwartz, Roy, Jesse Dodge, Noah A. Smith, and Oren Etzioni. "Green AI." *Communications of the ACM* 63, no. 12 (December 2020): 54--63. https://doi.org/10.1145/3381831.
* Selbst, Andrew D., Danah Boyd, Sorelle A. Friedler, Suresh Venkatasubramanian, and Janet Vertesi. "Fairness and Abstraction in Sociotechnical Systems." *FAT* '19: Proceedings of the Conference on Fairness, Accountability, and Transparency*, January 29, 2019, 59--68. https://doi.org/10.1145/3287560.3287598.
* Shneiderman, Ben. *Human-Centered AI*. Oxford: Oxford University Press, 2022.
* Shneiderman, Ben. "Human-Centered AI." *Issues in Science and Technology* 37, no. 2 (Winter 2021): 56--61. https://doi.org/https://issues.org/human-centered-ai/.
* Shneiderman, Ben. "Tutorial: Human-Centered AI: Reliable, Safe and Trustworthy." *IUI '21 Companion: 26th International Conference on Intelligent User Interfaces * Companion*, April 14, 2021, 7--8. https://doi.org/10.1145/3397482.3453994.
* Slack, Dylan, Sophie Hilgard, Emily Jia, Sameer Singh, and Himabindu Lakkaraju. "Fooling LIME and SHAP: Adversarial Attacks on Post Hoc Explanation Methods." *AIES '20: Proceedings of the AAAI/ACM Conference on AI, Ethics, and Society*, February 7, 2020, 180--86. https://doi.org/10.1145/3375627.3375830.
* Sloane, Mona, Emanuel Moss, Olaitan Awomolo, and Laura Forlano. "Participation Is Not a Design Fix for Machine Learning." *Equity and Access in Algorithms, Mechanisms, and Optimization*, October 2022. https://doi.org/10.1145/3551624.3555285.
* "Statement on Principles for Responsible Algorithmic Systems." *Association for Computing Machinery (ACM)*, October 26, 2022. ACM Technology Policy Council. https://www.acm.org/binaries/content/assets/public-policy/final-joint-ai-statement-update.pdf.
* Suresh, Harini, and John Guttag. "A Framework for Understanding Sources of Harm Throughout the Machine Learning Life Cycle." *Equity and Access in Algorithms, Mechanisms, and Optimization*, October 2021. https://doi.org/10.1145/3465416.3483305.
* Sweeney, Latanya. "K-Anonymity: A Model for Protecting Privacy." *International Journal of Uncertainty, Fuzziness and Knowledge-Based Systems* 10, no. 5 (2002): 557--70. https://doi.org/10.1142/s0218488502001648.
* Thomas, Rachel L., and David Uminsky. "Reliance on Metrics Is a Fundamental Challenge for AI." *Patterns* 3, no. 5 (May 13, 2022): 100476. https://doi.org/10.1016/j.patter.2022.100476.
* Thompson, Caitlin. "Who's Homeless Enough for Housing? In San Francisco, an Algorithm Decides." Coda, September 21, 2021. https://www.codastory.com/authoritarian-tech/san-francisco-homeless-algorithm/.
* Umbrello, Steven, and Ibo van de Poel. "Mapping Value Sensitive Design onto AI for Social Good Principles." *AI and Ethics* 1, no. 3 (February 1, 2021): 283--96. https://doi.org/10.1007/s43681-021-00038-3.
* Visengeriyeva, Larysa. "Visenger * Overview." GitHub, n.d. https://github.com/visenger.
* Winter, Jenifer Sunrise, and Elizabeth Davidson. "Big Data Governance of Personal Health Information and Challenges to Contextual Integrity." *The Information Society: An International Journal* 35, no. 1 (2019): 36--51. https://doi.org/10.1080/01972243.2018.1542648.
* Yang, Ke, Julia Stoyanovich, Abolfazl Asudeh, Bill Howe, HV Jagadish, and Gerome Miklau. "A Nutritional Label for Rankings." *SIGMOD '18: Proceedings of the 2018 International Conference on Management of Data*, May 27, 2018, 1773--76. https://doi.org/10.1145/3183713.3193568.
* Zerilli, John, Alistair Knott, James Maclaurin, and Colin Gavaghan. "Algorithmic Decision-Making and the Control Problem." *Minds and Machines* 29, no. 4 (December 11, 2019): 555--78. https://doi.org/10.1007/s11023-019-09513-7. 

